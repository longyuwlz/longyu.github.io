# cpu 分支预测对性能的影响

现在的 cpu 一般都支持分支预测功能。维基百科中有以下描述：

>在计算机体系结构中，分支预测器（英语：Branch predictor）是一种数字电路，在分支指令执行结束之前猜测哪一路分支将会被运行，以提高处理器的指令流水线的性能。使用分支预测器的目的，在于改善指令管线化的流程。现代使用指令管线化处理器的性能能够提高，分支预测器对于现今的指令流水线微处理器获得高性能是非常关键的技术。

cpu 预先对将要执行的分支进行预测，预测成功的概率越大，程序的性能就越好。分支预测实际是为流水线服务的，通过分支预测可以提高流水线的性能。当没有分支预测的情况下，cpu 只有当执行完成了当前分支指令之后才能确定要取哪一条指令来执行，也就是说在执行分支指令的同时，流水线中不能进入新的指令，这被称为流水线停顿。

分支预测可以避免流水线停顿的发生。不过当使用分支预测时，当预测失败后，将会带来更多的性能损耗。预测失败时 cpu 会放弃已经执行完成的结果，然后重新获取正确的分支中的指令开始执行。在较长的流水线中，一次分支预测失败可能会损失 10 ～ 20 个 cpu 周期的时间。

分支预测有多种实现方式，每一种方式都有它自己的特点与适应环境。大部分情况下我们无法关闭 cpu 的分支预测功能，少部分情况下是否能够关闭还有待研究。不过分支预测对程序员来说是一种黑盒，是不透明的，但程序员仍旧能够通过合理的调整分支结构来提高预测成功率。

在编写代码时，分支的排布将对性能造成影响。将发生概率大的分支放在前面有助于提高分支预测成功率。linux 中的 likely 与 unlikely 就是为了提高分支预测的成功率所使用的方法，尽管它依赖 gcc 的扩展功能！

**同时必须注意的是，流水线与分支预测在提高计算机性能的同时也给指令的执行了带入了更多的不可控因素。指令执行不再是传统的顺序执行的方式，这样既给问题定位带来了更大的挑战，也让程序具体的执行过程变得模糊不清。**

